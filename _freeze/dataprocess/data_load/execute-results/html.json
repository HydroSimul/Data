{
  "hash": "6ec7b30e48a8f359db6bb7bcac9be259",
  "result": {
    "markdown": "---\ntitle: \"Data Loading\"\nexecute:\n  warning: false\n  error: false\nsidebar:\n  contents: auto\nnumber-sections: true\n---\n\n\nThis Aritcl will show the process to load data from other files. I t will divide into four paties: plain text (read able ASCII), Excel, NetCDF and spatial data. \n\n# Plain text File\n\nFor more details about date (file) format, you can refer to the article titled [Basic Data & File Format](basic_format.qmd).\n\n## Example File\n\nLet's start with an example CSV file named `Bachum_2763190000100.csv`. This file contains pegel discharge data and is sourced from open data available at [ELWAS-WEB NRW](https://www.elwasweb.nrw.de/elwas-web/index.xhtml). You can also access it directly from the internet via [Github](https://raw.githubusercontent.com/HydroSimul/Web/main/data_share/Bachum_2763190000100.csv), just like you would access a local file.\n\nTake a look:\n\n\n![](../images/bachum.png)\n\n## Library and functions\n\n::: {.panel-tabset}\n\n## R\n\nFirst, we need to load the necessary library `tidyverse`. This library collection includes `readr` for reading files and `dplyr` for data manipulation, among others.\n\nAnd, we set the URL address as the file path (including the file name).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the library\nlibrary(tidyverse)\nfn_Bachum <- \"https://raw.githubusercontent.com/HydroSimul/Web/main/data_share/Bachum_2763190000100.csv\"\n```\n:::\n\n\nThe documentation for the `readr` library is available online and can be accessed at [https://readr.tidyverse.org](https://readr.tidyverse.org). \n\nOf particular interest are the following functions:\n\n- [readr::read_csv()](https://readr.tidyverse.org/reference/read_delim.html)\n- [readr::read_table()](https://readr.tidyverse.org/reference/read_table.html)\n\nWe can observe that the CSV file is divided by semicolons. Therefore, it's more appropriate to use `read_csv2()` rather than `read_csv()`.\n\nThe difference between `read_*()` functions in the `readr` package is determined by the delimiter character used in the files:\n\n\n![CHEAT SHEET from [Rstudio](https://github.com/rstudio/cheatsheets/blob/main/data-import.pdf)](../images/readr_read_.png)\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# load the library\nimport pandas as pd\nfn_Bachum = \"C:\\Lei\\HS_Web\\data_share/Bachum_2763190000100.csv\"\n```\n:::\n\n\nThe documentation for the `pandas` library is available online and can be accessed at [https://pandas.pydata.org/docs/index.html](https://pandas.pydata.org/docs/index.html). \n\nOf particular interest are the following functions:\n\n- [pandas.read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n- [pandas.read_table()](https://pandas.pydata.org/docs/reference/api/pandas.read_table.html)\n\n\n:::\n\n## Metadata Handel\n\nMetadata can vary widely between datasets, so it's handled separately from the data body.\n\nThere are three ways to deal with metadata:\n\n1. **Directly Ignore:** This approach involves ignoring metadata when it's redundant or readily available from other data sources, such as file names or external references.\n\n2. **Extract from Text:** When metadata is crucial but not in table form, you can extract information from text strings. For more information, refer to the section on string manipulation [@sec-string].\n\n3. **Read as a Second Table:** If metadata is well-organized in a tabular format, it can be read as a separate table to facilitate its use.\n\nIn the `Bachum_2763190000100.csv` file, you will find that there are 10 lines of metadata, which are well-organized in a tabular format. However, it's important to note that the consistency in values column varies.\n\n### Directly Ignore use grguments `skip`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# skip = 10\nread_csv2(fn_Bachum, skip = 10, n_max = 10, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   X1            X2\n   <chr>      <dbl>\n 1 01.01.1990  20.6\n 2 02.01.1990  19.0\n 3 03.01.1990  17.9\n 4 04.01.1990  16.8\n 5 05.01.1990  16.0\n 6 06.01.1990  14.8\n 7 07.01.1990  14.3\n 8 08.01.1990  14.0\n 9 09.01.1990  14.4\n10 10.01.1990  14.5\n```\n:::\n:::\n\n\n### Read metadata as table\n\nMore details in the next section:\n\n## Load tabular data\n\n::: {.panel-tabset}\n\n## R\n\n\n\nTo read the first 10 lines of metadata, you can use the `n_max` setting with a value of `n_max = 10` in the `read_csv2()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_csv2(fn_Bachum, n_max = 10, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   X1                          X2             \n   <chr>                       <chr>          \n 1 \"Name\"                      \"Bachum\"       \n 2 \"Pegelnummer\"               \"2763190000100\"\n 3 \"Gew\\xe4sser\"               \"Ruhr\"         \n 4 \"Datum von\"                 \"01.01.1990\"   \n 5 \"Datum bis\"                 \"31.12.2022\"   \n 6 \"Parameter\"                 \"Abfluss\"      \n 7 \"Q Einheit\"                 \"m\\xb3/s\"      \n 8 \"Tagesmittelwerte\"           <NA>          \n 9 \"Pegelnullpunkt [m\\xfcNHN]\" \"146,83\"       \n10 \"Einzugsgebiet [km\\xb2]\"    \"1.532,02\"     \n```\n:::\n:::\n\n\nAfter dealing with the metadata, we can proceed to load the data body using the `readr::read_*()` function cluster. \nPlain text files typically store data in a tabular or matrix format, both of which have at most two dimensions. \nWhen using the `readr::read_()` function, it automatically returns a `tibble`. If your data in the text file is in matrix format, you can use conversion functions like `as.matrix()` to transform it into other data structures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. load\ntb_Read <- read_csv2(fn_Bachum, skip = 10, n_max = 10, col_names = FALSE)\ntb_Read\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   X1            X2\n   <chr>      <dbl>\n 1 01.01.1990  20.6\n 2 02.01.1990  19.0\n 3 03.01.1990  17.9\n 4 04.01.1990  16.8\n 5 05.01.1990  16.0\n 6 06.01.1990  14.8\n 7 07.01.1990  14.3\n 8 08.01.1990  14.0\n 9 09.01.1990  14.4\n10 10.01.1990  14.5\n```\n:::\n\n```{.r .cell-code}\n# 2. convert\ndf_Read <- as.data.frame(tb_Read)\nmat_Read <- as.matrix(tb_Read)\n\ndf_Read\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           X1     X2\n1  01.01.1990 20.640\n2  02.01.1990 18.994\n3  03.01.1990 17.949\n4  04.01.1990 16.779\n5  05.01.1990 16.019\n6  06.01.1990 14.817\n7  07.01.1990 14.296\n8  08.01.1990 13.952\n9  09.01.1990 14.403\n10 10.01.1990 14.500\n```\n:::\n\n```{.r .cell-code}\nmat_Read\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      X1           X2      \n [1,] \"01.01.1990\" \"20.640\"\n [2,] \"02.01.1990\" \"18.994\"\n [3,] \"03.01.1990\" \"17.949\"\n [4,] \"04.01.1990\" \"16.779\"\n [5,] \"05.01.1990\" \"16.019\"\n [6,] \"06.01.1990\" \"14.817\"\n [7,] \"07.01.1990\" \"14.296\"\n [8,] \"08.01.1990\" \"13.952\"\n [9,] \"09.01.1990\" \"14.403\"\n[10,] \"10.01.1990\" \"14.500\"\n```\n:::\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntb_Read = pd.read_csv(fn_Bachum, skiprows=10, nrows=10, header=None, delimiter=';', decimal=',', encoding='latin-1')\nprint(tb_Read)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            0       1\n0  01.01.1990  20.640\n1  02.01.1990  18.994\n2  03.01.1990  17.949\n3  04.01.1990  16.779\n4  05.01.1990  16.019\n5  06.01.1990  14.817\n6  07.01.1990  14.296\n7  08.01.1990  13.952\n8  09.01.1990  14.403\n9  10.01.1990  14.500\n```\n:::\n:::\n\n\n:::\n\n## Data type {#sec-datatype}\n\nWhen directly reading all metadata into one table, you may encounter mixed data types. In the metadata, there are three data types:\n\n- Numeric: Examples include `Pegelnullpunkt` and `Einzugsgebiet`.\n- String: This category covers fields like `Name`, `Pegelnummer`, and others.\n- Date: Date values are present in columns like `Datum von` and `Datum bis`.\n\nIn a data frame (tibble), columns must have the same data type. Consequently, R will automatically convert them to a single data type, which is typically string.\n\nTo address this situation, you should specify the data type you want to read. For example, to read the date values in lines 4 and 5, you can use the following settings:\n1. `skip = 3` to skip the first three lines of metadata.\n2. `n_max = 2` to read the next two lines (lines 4 and 5) as date values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# skip = 10\nread_csv2(fn_Bachum, skip = 3, n_max = 2, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  X1        X2        \n  <chr>     <chr>     \n1 Datum von 01.01.1990\n2 Datum bis 31.12.2022\n```\n:::\n:::\n\n\nUnfortunately, R may not always recognize date values correctly, so you may need to perform additional steps for conversion:\n\n1. **After Reading:** This involves transforming the data from its initial format to the desired date format within your R environment.\n\n2. **Set the Data Type by Reading:** Another approach is to set the data type while reading the data. \n\nTo address the issue of date recognition, you can set the `col_types` parameter to `\"cD\"` when reading the data. This informs the function that the first column contains `c`haracters (`c`) and the second column contains `D`ates (`D`).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# skip = 10\nread_csv2(fn_Bachum, skip = 3, n_max = 2, col_names = FALSE, col_types = \"cD\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  X1        X2    \n  <chr>     <date>\n1 Datum von NA    \n2 Datum bis NA    \n```\n:::\n:::\n\n\n\nUnfortunately, the default date format in R may not work for German-style dates like \"d.m.Y,\" as R primarily recognizes the \"Y-m-d\" format. To handle this, you can convert the dates using function `as.Date()` and specify the date format using the `format` argument, such as `format = \"%d.%m.%Y\"`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_Date <- read_csv2(fn_Bachum, skip = 3, n_max = 2, col_names = FALSE)\ndf_Date$X2 <- df_Date$X2 |> as.Date(format = \"%d.%m.%Y\")\ndf_Date\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  X1        X2        \n  <chr>     <date>    \n1 Datum von 1990-01-01\n2 Datum bis 2022-12-31\n```\n:::\n:::\n\n\n\n\n\n\n\n# Excel File\n\nWhen we discuss the combination of the software Excel with data files in formats such as .xls or .xlsx, there are numerous possibilities for data science. However, when we specifically consider the file format, there are distinct differences between plain text and Excel files:\n\n**Plain Text File vs. Excel for Data Storage**\n\n| Aspect                      | Plain Text File                   | Excel File                            |\n|-----------------------------|-----------------------------------|--------------------------------------|\n| **Data Structure**          | Typically stores data in a tabular format or matrix. | Stores data in structured worksheets with multiple tables (sheets). |\n| **Compatibility**           | Universally compatible with various software and programming languages. | Compatibility may vary, and not all software can read Excel files. |\n| **Human-Readable**          | Easily readable by humans in a simple text format. | Readable by humans but may include formatting that isn't immediately apparent. |\n| **Data Transfer**           | Easily shared and transferred between different platforms and systems. | May require conversion or specific software for seamless data transfer. |\n| **Data Import/Export**      | May require custom import/export scripts for specific applications. | Supports standardized import/export formats for various applications. |\n| **Version Control**         | Suitable for version control systems (e.g., Git) for tracking changes. | Not well-suited for version control due to binary format and complex changes. |\n| **Data Analysis**           | Requires additional software to analyze data (e.g., R or Python). | Offers built-in data analysis tools (e.g., formulas, charts). |\n| **Openness and Access**     | Open and transparent; data can be accessed and edited with any text editor. | Proprietary format may require specific software (Microsoft Excel) to access and edit. |\n\n\nUnlike plain text files, Excel files have the capability to contain multiple tables, known as sheets. In Excel, each cell within a sheet is uniquely identified by its specific coordinates. Rows are indexed with numerical values, and columns are identified using alphabetical indices. By combining the sheet name with these coordinates, it is possible to precisely locate any cell within an Excel file and retrieve the value it contains.\n\n\n## Example File\n\nLet's begin with an example Excel file named `Pegeln_NRW.xlsx`. This file contains information about measurement stations in NRW (Nordrhein-Westfalen, Germany) and is sourced from open data available at [ELWAS-WEB NRW](https://www.elwasweb.nrw.de/elwas-web/index.xhtml). You can also access it directly from  [Github](https://github.com/HydroSimul/Web/blob/main/data_share/Pegeln_NRW.xlsx).\n\nTake a look:\n\n![](../images/dataload_excel_pegeln.png)\n\n\n## R library and functions\n\nTo load the necessary library, `readxl`, and access its help documentation, you can visit [this link](https://readxl.tidyverse.org/). The `readxl::read_excel()` function is versatile, as it can read both .xls and .xlsx files and automatically detects the format based on the file extension. Additionally, you have the options of using `read_xls()` for .xls files and `read_xlsx()` for .xlsx files. More details in the [Page](https://readxl.tidyverse.org/reference/read_excel.html).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the library\nlibrary(readxl)\n# The Excel file cannot be read directly from GitHub. You will need to download it to your local machine first\nfn_Pegeln <- \"C:\\\\Lei\\\\HS_Web\\\\data_share/Pegeln_NRW.xlsx\"\n```\n:::\n\n\n\n## Load tabular data\n\nSimilar to plain text files, metadata is often provided before the data body in Excel files. \nIn Excel, each cell can be assigned a specific data type, while in R tables (data.frame or tibble), every column must have the same data type. This necessitates separate handling of metadata and data body to ensure that the correct data types are maintained.\n\nUnlike plain text files where we can only select lines to load, Excel allows us to define coordinates to access a specific celles-box wherever they are located.\n\n### First try without any setting\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# try without setting\ntb_Pegeln <- read_excel(fn_Pegeln)\ntb_Pegeln\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 277 × 16\n   Suchergebnisse Pegel.…¹ ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10\n   <chr>                   <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n 1 \"Suchkriterien:\\n -- \\… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 2  <NA>                   <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 3  <NA>                   <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 4 \"Name\"                  Pege… Gewä… Betr… Pege… Einz… Q von Q bis NQ    MNQ  \n 5 \"Ahlen\"                 3211… Werse LANU… 73,47 46,62 1975  2013  0     0,07 \n 6 \"Ahmsen\"                4639… Werre LANU… 64,28 593   1963  2022  1,21  2,22 \n 7 \"Ahrhütte-Neuhof\"       2718… Ahr   LANU… 340,… 124   1986  2011  0,22  0,36 \n 8 \"Albersloh\"             3259… Werse LANU… 48,68 321,… 1973  2020  0,12  0,24 \n 9 \"Altena\"                2766… Lenne LANU… 154,… 1.190 1950  2021  1,36  6,48 \n10 \"Altena_Rahmedestraße\"  2766… Rahm… LANU… 157,… 29,6  <NA>  <NA>  <NA>  <NA> \n# ℹ 267 more rows\n# ℹ abbreviated name: ¹​`Suchergebnisse Pegel.xlsx 14.09.2023 10:01`\n# ℹ 6 more variables: ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>,\n#   ...15 <chr>, ...16 <chr>\n```\n:::\n:::\n\n\n\nWhen we provide only the file name to the function, we will always retrieve all the content from the first sheet. However, due to the limitations in R tables, every column will be recognized as the same data type, typically character.\n\n### Give a `range`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# using the range argument\ntb_Pegeln_Range <- read_excel(fn_Pegeln, range = \"Suchergebnisse Pegel!A5:P10\")\ntb_Pegeln_Range\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 16\n  Name            Pegelnummer   Gewässername Betreiber  `Pegelnullpunkt [müNHN]`\n  <chr>           <chr>         <chr>        <chr>      <chr>                   \n1 Ahlen           3211000000300 Werse        LANUV, NRW 73,47                   \n2 Ahmsen          4639000000100 Werre        LANUV, NRW 64,28                   \n3 Ahrhütte-Neuhof 2718193000100 Ahr          LANUV, NRW 340,58                  \n4 Albersloh       3259000000100 Werse        LANUV, NRW 48,68                   \n5 Altena          2766930000100 Lenne        LANUV, NRW 154,22                  \n# ℹ 11 more variables: `Einzugsgebiet [km²]` <chr>, `Q von` <chr>,\n#   `Q bis` <chr>, NQ <chr>, MNQ <chr>, MQ <chr>, MHQ <chr>, HQ <chr>,\n#   `Q Einheit` <chr>, `Ostwert in UTM` <chr>, `Nordwert in UTM` <chr>\n```\n:::\n:::\n\n\n::: {.callout-warning}\nThe data type of \"Pegelnullpunkt [müNHN]\" appears to be incorrect due to improper settings in Excel.\n:::\n\n\n## Data type\n\nCompared to plain text files, Excel data already contains data type information for each cell. Therefore, the data type will be directly determined by the data type specified in Excel.\n\nHowever, there are instances where the data type in Excel is not correctly set, so manual data type conversion may be necessary. For more details, refer to [@sec-datatype].\n\n\n# NetCDF\n\nthe process loading of netCDF is seperated in the page\n\n# Text & String {#sec-string}\n\nmore details ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}