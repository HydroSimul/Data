{
  "hash": "c519fd7e6793bdd242412b05d49de79c",
  "result": {
    "markdown": "---\ntitle: \"Statistic Basic\"\nexecute:\n  warning: false\n  error: false\nsidebar:\n  contents: auto\nnumber-sections: true\nbibliography: ../../references.bib\n---\n\n\n\n# Statistic\n\nOne of the most important tasks while analyzing any time series is to describe and summarize the time series data in forms, which easily convey their important characteristics.\n\nKey statistical characteristics often described include: a measure of the **central tendency** of the data, a measure of **spread or variability**, a measure of the **symmetry** of the data distribution, and perhaps estimates of extremes such as some large or small percentile [@StatisticalMethods_snedecor_1980].\n\n## Population and Sample\n\nAccording to Helsel and Hirsch [-@StatisticWater_helsel_2020], the data about which a statement or summary is to be made are called **‘population’** or sometimes ‘target population’. It may be impossible both physically and economically to collect all data of interest.\nAlternatively, a **subset** of the entire data called **‘sample’** is selected and measured in such a way that conclusions about the sample may be extended to the entire population.\n\n\n## Measures of Location\n\n\nIn statistics, measures of location or central tendency are used to summarize and describe the central or typical value in a dataset. Here are the six common measures of location [@HydroTimeSeries_machiwal_2012]:\n\n- **Mean**: The mean, often referred to as the **average**, is calculated by summing all the values in a dataset and dividing by the number of values. It represents the **balance** point of the data.\n\n- **Median**: The median is the **middle** value when the data is sorted in ascending order. It's less sensitive to extreme values (outliers) than the mean and is a good measure of the central value *when the data is skewed*.\n\n- **Mode**: The mode is the value that appears **most frequently** in the dataset. There can be multiple modes in a dataset, and it's useful for categorical or discrete data.\n\n- **Geometric Mean**: The geometric mean is used for data that is **not normally distributed**, such as financial returns or growth rates. It's calculated by taking the nth root of the product of n values.\n\n- **Trimmed Mean**: The trimmed mean is a variation of the mean that **removes a certain percentage of extreme values** (usually a specified percentage from both tails of the distribution) before calculating the mean. This makes it more robust to outliers.\n\nAmong these measures, the mean and median are the most widely used for summarizing data. \n\n\n### Arithmetic Mean\n\nThe arithmetic mean ($\\overline{{x}}$) is calculated by summing up of all data values, $x_{\\mathrm{i}}$ and dividing the sum by the sample size $n$:\n\n\n$$\n{\\overline{{x}}}=\\sum_{i=1}^{n}{\\frac{x_{\\mathrm{i}}}{n}} \n$$\n\n### Median\n\nThe median is the middle value in a dataset when the data is ordered from smallest to largest. It's a robust measure of central tendency that is not influenced by extreme values (outliers).\n\n\nFor an ordered dataset with 'n' values:\n\n- If 'n' is odd, the median is the middle value: \n$$\n\\text{M} = x_{\\frac{n+1}{2}} \n$$\n\n- If 'n' is even, the median is the average of the two middle values: \n$$ \n\\text{M} = \\frac{x_{\\frac{n}{2}} + x_{\\frac{n}{2}+1}}{2} \n$$\n\n\n\n\n### Geometric Mean\n\nThe geometric mean (GM) is often used to compute summary statistic for positively skewed datasets [@HydroTimeSeries_machiwal_2012].\n\n\n\n\n$$\n{\\mathrm{GM}}={\\mathrm{exp}}\\left[\\sum_{i=1}^{n}{\\frac{\\ln\\left(x_{\\mathrm{i}}\\right)}{n}}\\right] \n$$\n\nFor the positively skewed data series, the GM is usually fairly close to the median of the series. In fact, the GM is an unbiased estimate of the median when the logarithms of the datasets are symmetric [@StatisticWater_helsel_2020].\n\n\n## Measures of Spread/Dispersion\n\n\n### Variance and Standard Deviation\n\nThe ‘sample variance’ and ‘sample standard deviation’ (square root of sample variance) are classical measures of spread (dispersion), which are the most common measures of dispersion [@HydroTimeSeries_machiwal_2012].\n\n\n$$\ns^{2}=\\sum_{i=1}^{n}\\frac{\\left(x_{\\mathrm{i}}-{\\overline{{x}}}\\,\\right)^{2}}{\\left(n-1\\right)} \n$$\n\n\n\n$$\ns={\\sqrt{\\sum_{i=1}^{n}{\\frac{\\left(x_{i}-{\\overline{{x}}}\\,\\right)^{2}}{\\left(n-1\\right)}}}} \n$$\n\n### Robust Measures\n\nRobust measures of spreading about the mean include **‘range’**, ‘interquartile range’, ‘coefficient of variation’ and ‘median absolute deviation’ [@HydroTimeSeries_machiwal_2012].\n\n\n#### Quantiles\n\n**Quantiles** are values that divide a dataset into equally sized subsets. Common quantiles include **quartiles** (dividing data into four parts), **quintiles** (dividing into five parts), **deciles** (dividing into ten parts), and **percentiles** (dividing into one hundred parts).\n\n\n- Sort the dataset in ascending order.\n- Compute the index 'i' as \n\n$$ \ni = \\text{round}((n+1) \\cdot q) \n$$\n\n- If 'i' is an integer, the quantile is \n\n$$ \n\\text{Q}(q) = x_i \n$$\n- If 'i' is not an integer, the quantile is interpolated as \n\n$$ \n\\text{Q}(q) = x_{\\lfloor i \\rfloor} + (i - \\lfloor i \\rfloor) \\cdot (x_{\\lfloor i \\rfloor + 1} - x_{\\lfloor i \\rfloor}) \n$$\n\nQuantiles are used to understand the spread and distribution of data and are often used in box plots and histograms to visualize data distribution.\n\n#### coefficient of variation\n\nThe coefficient of variation (CV) gives a normalized measure of spreading about the mean, and is estimated as [@HydroTimeSeries_machiwal_2012]:\n\n\n\n$$\n\\mathbf{C}\\mathbf{V}(\\vartheta_{0})={\\frac{s}{\\bar{x}}}\\times100 \n$$\n\n\nHydrologic variables with larger CV values are more variable than those with smaller values. Wilding (in [@SoilSpatialVariability_nielsen_1985]) suggested a classification scheme for identifying the extent of variability for soil properties based on their CV values, where CV values of 0-15, 16-35 and >36 indicate little, moderate and high variability, respectively.\n\n#### Quartile coefficient\n\nQuartile coefficient (QC) of dispersion is another descriptive statistic which measures dispersion and is used to make comparison within and between datasets. The test-statistic is computed using the first (P25) and third (P75) quartiles for each data set. The quartile coefficient of dispersion (QC) is given as [@HydroTimeSeries_machiwal_2012]:\n\n\n\n$$\n\\text{QC}={\\frac{P_{75}-P_{25}}{P_{75}+P_{25}}} \n$$\n\n## Measures of Skewness\n\nHydrologic time series data are usually **skewed**, which means that data in the time series are **not symmetric** around the mean or median, with extreme values extending out longer in one direction [@HydroTimeSeries_machiwal_2012].\n\n\n### coefficient of skewness\n\nIt is defined as the adjusted third moment about the mean divided by the cube of the standard deviation (s), and is mathematically expressed as follows:\n\n$$\ng={\\frac{n}{\\left(n-1\\right)\\,\\left(n-2\\right)}}\\sum_{i=1}^{n}{\\frac{\\left(x_{i}-{\\overline{{x}}}\\,\\right)^{3}}{s^{3}}} \n$$\n\n\nA positively skewed distribution of hydrologic time series with right extended tail has a positive coefficient of skewness, whereas a time series with negative-skewed distribution with left extended tail has a negative coefficient of skewness [@HydroTimeSeries_machiwal_2012].\n\n\n### quartile skew coefficient (Robust Measure)\n\nA robust measure of skewness is the ‘quartile skew coefficient (QS)’, which is defined as the difference in distances of the upper and lower quartiles from the median, divided by the IQR [@MathStatistic_kenneyjohnf_1939]. Mathematically, it is expressed as:\n\n$$\n\\text{QS}=\\frac{\\left(P_{75}-P_{50}\\,\\right)-\\left(P_{50}-P_{25}\\,\\right)}{P_{75}-P_{25}} \n$$\n\n# Skript (R & Python)\n\n::: {.panel-tabset}\n\n## R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(moments)\n# Sample dataset (replace with your data)\ndata <- c(12, 15, 18, 22, 24, 28, 31, 35, 40, 45, 50)\n\n# Calculate Mean\nmean_value <- mean(data)\n\n# Calculate Median\nmedian_value <- median(data)\n\n# Calculate Variance\nvariance_value <- var(data)\n\n# Calculate Standard Deviation\nstd_deviation_value <- sd(data)\n\n# Calculate Quantiles (25th, 50th, and 75th percentiles)\nquantiles_values <- quantile(data, probs = c(0.25, 0.5, 0.75))\n\n# Calculate Skewness\nskewness_value <- moments::skewness(data)\n\n# Print the results\ncat(\"Mean:\", mean_value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean: 29.09091 \n```\n:::\n\n```{.r .cell-code}\ncat(\"Median:\", median_value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMedian: 28 \n```\n:::\n\n```{.r .cell-code}\ncat(\"Variance:\", variance_value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVariance: 153.8909 \n```\n:::\n\n```{.r .cell-code}\ncat(\"Standard Deviation:\", std_deviation_value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStandard Deviation: 12.40528 \n```\n:::\n\n```{.r .cell-code}\ncat(\"Quantiles (25th, 50th, 75th percentiles):\", quantiles_values, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nQuantiles (25th, 50th, 75th percentiles): 20 28 37.5 \n```\n:::\n\n```{.r .cell-code}\ncat(\"Skewness:\", skewness_value, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSkewness: 0.2766313 \n```\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nfrom scipy.stats import skew\n\n# Sample dataset (replace with your data)\ndata = np.array([12, 15, 18, 22, 24, 28, 31, 35, 40, 45, 50])\n\n# Calculate Mean\nmean_value = np.mean(data)\n\n# Calculate Median\nmedian_value = np.median(data)\n\n# Calculate Variance\nvariance_value = np.var(data, ddof=0)  # Set ddof to 0 for population variance\n\n# Calculate Standard Deviation\nstd_deviation_value = np.std(data, ddof=0)  # Set ddof to 0 for population standard deviation\n\n# Calculate Quantiles (25th, 50th, and 75th percentiles)\nquantiles_values = np.percentile(data, [25, 50, 75])\n\n# Calculate Skewness\nskewness_value = skew(data)\n\nprint(\"Mean:\", mean_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean: 29.09090909090909\n```\n:::\n\n```{.python .cell-code}\nprint(\"Median:\", median_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMedian: 28.0\n```\n:::\n\n```{.python .cell-code}\nprint(\"Variance:\", variance_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nVariance: 139.900826446281\n```\n:::\n\n```{.python .cell-code}\nprint(\"Standard Deviation:\", std_deviation_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStandard Deviation: 11.82796797621134\n```\n:::\n\n```{.python .cell-code}\nprint(\"Quantiles (25th, 50th, 75th percentiles):\", quantiles_values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nQuantiles (25th, 50th, 75th percentiles): [20.  28.  37.5]\n```\n:::\n\n```{.python .cell-code}\nprint(\"Skewness:\", skewness_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSkewness: 0.27663130070935216\n```\n:::\n:::\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}